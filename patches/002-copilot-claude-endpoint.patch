# PATCH 002: Route Copilot models to correct endpoints
#
# Routes GPT-5 models to /responses (codex translator), Claude models to
# /v1/messages (claude translator), and others to /chat/completions (openai).
# Strips copilot- prefix from model names (replaces old patch 005).
# Handles thinking/budget_tokens for Claude, adds anthropic-beta header,
# parses Claude usage stats, and skips OpenAI-specific processing for Claude.
# Applies to both Execute (non-streaming) and ExecuteStream (streaming) paths.
--- a/internal/runtime/executor/github_copilot_executor.go	2026-02-20 18:27:35.427194899 +0000
+++ b/internal/runtime/executor/github_copilot_executor.go	2026-02-20 18:27:42.315222095 +0000
@@ -27,6 +27,7 @@
 	githubCopilotBaseURL       = "https://api.githubcopilot.com"
 	githubCopilotChatPath      = "/chat/completions"
 	githubCopilotResponsesPath = "/responses"
+	githubCopilotMessagesPath  = "/v1/messages"
 	githubCopilotAuthType      = "github-copilot"
 	githubCopilotTokenCacheTTL = 25 * time.Minute
 	// tokenExpiryBuffer is the time before expiry when we should refresh the token.
@@ -83,7 +84,7 @@
 	if errToken != nil {
 		return errToken
 	}
-	e.applyHeaders(req, apiToken, nil)
+	e.applyHeaders(req, apiToken, sdktranslator.Format(""), nil)
 	return nil
 }
 
@@ -114,11 +115,14 @@
 	defer reporter.trackFailure(ctx, &err)
 
 	from := opts.SourceFormat
-	useResponses := useGitHubCopilotResponsesEndpoint(from, req.Model)
-	to := sdktranslator.FromString("openai")
-	if useResponses {
-		to = sdktranslator.FromString("openai-response")
+	useClaude := isCopilotClaudeModel(req.Model) && from == sdktranslator.FormatClaude
+	toFormat := "openai"
+	if useClaude {
+		toFormat = "claude"
+	} else if isGPT5Model(req.Model) {
+		toFormat = "codex"
 	}
+	to := sdktranslator.FromString(toFormat)
 	originalPayload := bytes.Clone(req.Payload)
 	if len(opts.OriginalRequest) > 0 {
 		originalPayload = bytes.Clone(opts.OriginalRequest)
@@ -126,43 +130,47 @@
 	originalTranslated := sdktranslator.TranslateRequest(from, to, req.Model, originalPayload, false)
 	body := sdktranslator.TranslateRequest(from, to, req.Model, bytes.Clone(req.Payload), false)
 	body = e.normalizeModel(req.Model, body)
-	body = flattenAssistantContent(body)
+	if !useClaude {
+		body = flattenAssistantContent(body)
+	}
 
 	// Detect vision content before input normalization removes messages
 	hasVision := detectVisionContent(body)
 
-	thinkingProvider := "openai"
-	if useResponses {
-		thinkingProvider = "codex"
-	}
-	body, err = thinking.ApplyThinking(body, req.Model, from.String(), thinkingProvider, e.Identifier())
-	if err != nil {
-		return resp, err
-	}
+	if !useClaude {
+		if isGPT5Model(req.Model) {
+			body = normalizeGitHubCopilotResponsesTools(body)
+		} else {
+			body = normalizeGitHubCopilotChatTools(body)
+		}
 
-	if useResponses {
-		body = normalizeGitHubCopilotResponsesInput(body)
-		body = normalizeGitHubCopilotResponsesTools(body)
-	} else {
-		body = normalizeGitHubCopilotChatTools(body)
+		thinkingProvider := "openai"
+		if isGPT5Model(req.Model) {
+			thinkingProvider = "codex"
+		}
+		body, err = thinking.ApplyThinking(body, req.Model, from.String(), thinkingProvider, e.Identifier())
+		if err != nil {
+			return resp, err
+		}
 	}
+
 	requestedModel := payloadRequestedModel(opts, req.Model)
 	body = applyPayloadConfigWithRoot(e.cfg, req.Model, to.String(), "", body, originalTranslated, requestedModel)
+	if isCopilotClaudeFormat(to) {
+		body = normalizeCopilotClaudeThinking(req.Model, body)
+	}
 	body, _ = sjson.SetBytes(body, "stream", false)
+	body, _ = sjson.DeleteBytes(body, "stream_options")
 
-	path := githubCopilotChatPath
-	if useResponses {
-		path = githubCopilotResponsesPath
-	}
-	url := baseURL + path
+	url := baseURL + getCopilotEndpointPath(req.Model, to)
 	httpReq, err := http.NewRequestWithContext(ctx, http.MethodPost, url, bytes.NewReader(body))
 	if err != nil {
 		return resp, err
 	}
-	e.applyHeaders(httpReq, apiToken, body)
+	e.applyHeaders(httpReq, apiToken, to, body)
 
 	// Add Copilot-Vision-Request header if the request contains vision content
-	if hasVision {
+	if !useClaude && hasVision {
 		httpReq.Header.Set("Copilot-Vision-Request", "true")
 	}
 
@@ -214,7 +222,9 @@
 	appendAPIResponseChunk(ctx, e.cfg, data)
 
 	detail := parseOpenAIUsage(data)
-	if useResponses && detail.TotalTokens == 0 {
+	if detail.TotalTokens == 0 && useClaude {
+		detail = parseClaudeUsage(data)
+	} else if detail.TotalTokens == 0 {
 		detail = parseOpenAIResponsesUsage(data)
 	}
 	if detail.TotalTokens > 0 {
@@ -223,11 +233,7 @@
 
 	var param any
 	converted := ""
-	if useResponses && from.String() == "claude" {
-		converted = translateGitHubCopilotResponsesNonStreamToClaude(data)
-	} else {
-		converted = sdktranslator.TranslateNonStream(ctx, to, from, req.Model, bytes.Clone(opts.OriginalRequest), body, data, &param)
-	}
+	converted = sdktranslator.TranslateNonStream(ctx, to, from, req.Model, bytes.Clone(opts.OriginalRequest), body, data, &param)
 	resp = cliproxyexecutor.Response{Payload: []byte(converted)}
 	reporter.ensurePublished(ctx)
 	return resp, nil
@@ -244,11 +250,14 @@
 	defer reporter.trackFailure(ctx, &err)
 
 	from := opts.SourceFormat
-	useResponses := useGitHubCopilotResponsesEndpoint(from, req.Model)
-	to := sdktranslator.FromString("openai")
-	if useResponses {
-		to = sdktranslator.FromString("openai-response")
+	useClaude := isCopilotClaudeModel(req.Model) && from == sdktranslator.FormatClaude
+	toFormat := "openai"
+	if useClaude {
+		toFormat = "claude"
+	} else if isGPT5Model(req.Model) {
+		toFormat = "codex"
 	}
+	to := sdktranslator.FromString(toFormat)
 	originalPayload := bytes.Clone(req.Payload)
 	if len(opts.OriginalRequest) > 0 {
 		originalPayload = bytes.Clone(opts.OriginalRequest)
@@ -256,47 +265,51 @@
 	originalTranslated := sdktranslator.TranslateRequest(from, to, req.Model, originalPayload, false)
 	body := sdktranslator.TranslateRequest(from, to, req.Model, bytes.Clone(req.Payload), true)
 	body = e.normalizeModel(req.Model, body)
-	body = flattenAssistantContent(body)
+	if !useClaude {
+		body = flattenAssistantContent(body)
+	}
 
 	// Detect vision content before input normalization removes messages
 	hasVision := detectVisionContent(body)
 
-	thinkingProvider := "openai"
-	if useResponses {
-		thinkingProvider = "codex"
-	}
-	body, err = thinking.ApplyThinking(body, req.Model, from.String(), thinkingProvider, e.Identifier())
-	if err != nil {
-		return nil, err
-	}
+	if !useClaude {
+		if isGPT5Model(req.Model) {
+			body = normalizeGitHubCopilotResponsesTools(body)
+		} else {
+			body = normalizeGitHubCopilotChatTools(body)
+		}
 
-	if useResponses {
-		body = normalizeGitHubCopilotResponsesInput(body)
-		body = normalizeGitHubCopilotResponsesTools(body)
-	} else {
-		body = normalizeGitHubCopilotChatTools(body)
+		thinkingProvider := "openai"
+		if isGPT5Model(req.Model) {
+			thinkingProvider = "codex"
+		}
+		body, err = thinking.ApplyThinking(body, req.Model, from.String(), thinkingProvider, e.Identifier())
+		if err != nil {
+			return nil, err
+		}
 	}
+
 	requestedModel := payloadRequestedModel(opts, req.Model)
 	body = applyPayloadConfigWithRoot(e.cfg, req.Model, to.String(), "", body, originalTranslated, requestedModel)
+	if isCopilotClaudeFormat(to) {
+		body = normalizeCopilotClaudeThinking(req.Model, body)
+	}
 	body, _ = sjson.SetBytes(body, "stream", true)
-	// Enable stream options for usage stats in stream
-	if !useResponses {
+	if !isCopilotClaudeFormat(to) {
 		body, _ = sjson.SetBytes(body, "stream_options.include_usage", true)
+	} else {
+		body, _ = sjson.DeleteBytes(body, "stream_options")
 	}
 
-	path := githubCopilotChatPath
-	if useResponses {
-		path = githubCopilotResponsesPath
-	}
-	url := baseURL + path
+	url := baseURL + getCopilotEndpointPath(req.Model, to)
 	httpReq, err := http.NewRequestWithContext(ctx, http.MethodPost, url, bytes.NewReader(body))
 	if err != nil {
 		return nil, err
 	}
-	e.applyHeaders(httpReq, apiToken, body)
+	e.applyHeaders(httpReq, apiToken, to, body)
 
 	// Add Copilot-Vision-Request header if the request contains vision content
-	if hasVision {
+	if !useClaude && hasVision {
 		httpReq.Header.Set("Copilot-Vision-Request", "true")
 	}
 
@@ -366,9 +379,13 @@
 				if bytes.Equal(data, []byte("[DONE]")) {
 					continue
 				}
-				if detail, ok := parseOpenAIStreamUsage(line); ok {
+				if useClaude {
+					if detail, ok := parseClaudeStreamUsage(line); ok {
+						reporter.publish(ctx, detail)
+					}
+				} else if detail, ok := parseOpenAIStreamUsage(line); ok {
 					reporter.publish(ctx, detail)
-				} else if useResponses {
+				} else if isGPT5Model(req.Model) {
 					if detail, ok := parseOpenAIResponsesStreamUsage(line); ok {
 						reporter.publish(ctx, detail)
 					}
@@ -376,7 +393,7 @@
 			}
 
 			var chunks []string
-			if useResponses && from.String() == "claude" {
+			if isGPT5Model(req.Model) && !useClaude && from.String() == "claude" {
 				chunks = translateGitHubCopilotResponsesStreamToClaude(bytes.Clone(line), &param)
 			} else {
 				chunks = sdktranslator.TranslateStream(ctx, to, from, req.Model, bytes.Clone(opts.OriginalRequest), body, bytes.Clone(line), &param)
@@ -479,7 +496,7 @@
 }
 
 // applyHeaders sets the required headers for GitHub Copilot API requests.
-func (e *GitHubCopilotExecutor) applyHeaders(r *http.Request, apiToken string, body []byte) {
+func (e *GitHubCopilotExecutor) applyHeaders(r *http.Request, apiToken string, format sdktranslator.Format, body []byte) {
 	r.Header.Set("Content-Type", "application/json")
 	r.Header.Set("Authorization", "Bearer "+apiToken)
 	r.Header.Set("Accept", "application/json")
@@ -495,6 +512,9 @@
 	r.Header.Set("X-Initiator", "agent")
 	r.Header.Set("VScode-SessionId", uuid.NewString())
 	r.Header.Set("VScode-MachineId", uuid.NewString())
+	if isCopilotClaudeFormat(format) {
+		r.Header.Set("anthropic-beta", copilotThinkingBeta)
+	}
 }
 
 // detectVisionContent checks if the request body contains vision/image content.
@@ -525,11 +545,14 @@
 	return false
 }
 
-// normalizeModel strips the suffix (e.g. "(medium)") from the model name
-// before sending to GitHub Copilot, as the upstream API does not accept
-// suffixed model identifiers.
+// normalizeModel strips the suffix (e.g. "(medium)") and the "copilot-" alias
+// prefix from the model name before sending to GitHub Copilot, as the upstream
+// API does not accept suffixed or prefixed model identifiers.
 func (e *GitHubCopilotExecutor) normalizeModel(model string, body []byte) []byte {
 	baseModel := thinking.ParseSuffix(model).ModelName
+	if strings.HasPrefix(baseModel, "copilot-") {
+		baseModel = strings.TrimPrefix(baseModel, "copilot-")
+	}
 	if baseModel != model {
 		body, _ = sjson.SetBytes(body, "model", baseModel)
 	}
@@ -544,6 +567,79 @@
 	return strings.Contains(baseModel, "codex")
 }
 
+// isGPT5Model checks if the model is a GPT-5 series model that requires the /responses endpoint.
+func isGPT5Model(model string) bool {
+	normalized := strings.TrimPrefix(model, "copilot-")
+	return strings.HasPrefix(normalized, "gpt-5")
+}
+
+// isCopilotClaudeModel checks if the model is a Claude model that should use
+// the /v1/messages endpoint on GitHub Copilot.
+func isCopilotClaudeModel(model string) bool {
+	normalized := strings.TrimPrefix(model, "copilot-")
+	return strings.HasPrefix(normalized, "claude-")
+}
+
+func isCopilotClaudeFormat(format sdktranslator.Format) bool {
+	return format == sdktranslator.FormatClaude
+}
+
+func getCopilotEndpointPath(model string, format sdktranslator.Format) string {
+	if isCopilotClaudeFormat(format) {
+		return githubCopilotMessagesPath
+	}
+	if isGPT5Model(model) {
+		return githubCopilotResponsesPath
+	}
+	return githubCopilotChatPath
+}
+
+func normalizeCopilotClaudeThinking(model string, body []byte) []byte {
+	normalized := strings.ToLower(strings.TrimPrefix(model, "copilot-"))
+	supportsThinking := strings.Contains(normalized, "sonnet-4") ||
+		strings.Contains(normalized, "3-5-sonnet") ||
+		strings.Contains(normalized, "3.5-sonnet") ||
+		strings.Contains(normalized, "3-7-sonnet") ||
+		strings.Contains(normalized, "3.7-sonnet") ||
+		strings.Contains(normalized, "opus-4")
+	if !supportsThinking {
+		if updated, err := sjson.DeleteBytes(body, "thinking"); err == nil {
+			return updated
+		}
+		return body
+	}
+	thinkingVal := gjson.GetBytes(body, "thinking")
+	if !thinkingVal.Exists() {
+		return body
+	}
+	thinkingType := strings.ToLower(strings.TrimSpace(thinkingVal.Get("type").String()))
+	if thinkingType == "disabled" {
+		return body
+	}
+	maxTokens := gjson.GetBytes(body, "max_tokens")
+	maxVal := int(maxTokens.Int())
+	if maxVal <= 0 {
+		maxVal = 16000
+		body, _ = sjson.SetBytes(body, "max_tokens", maxVal)
+	}
+	budgetVal := int(thinkingVal.Get("budget_tokens").Int())
+	if budgetVal <= 0 {
+		budgetVal = 10000
+	}
+	if budgetVal < 1024 {
+		budgetVal = 1024
+	}
+	if budgetVal > 128000 {
+		budgetVal = 128000
+	}
+	if budgetVal >= maxVal {
+		budgetVal = maxVal - 1
+	}
+	body, _ = sjson.SetBytes(body, "thinking.type", "enabled")
+	body, _ = sjson.SetBytes(body, "thinking.budget_tokens", budgetVal)
+	return body
+}
+
 // flattenAssistantContent converts assistant message content from array format
 // to a joined string. GitHub Copilot requires assistant content as a string;
 // sending it as an array causes Claude models to re-answer all previous prompts.
